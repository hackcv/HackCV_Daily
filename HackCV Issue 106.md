+++
author = "cvley"
categories = ["资讯日报"]
title = "第196期 HackCV 日报"
tags = ["机器学习","神经网络","词嵌入"]
date = "2018-04-16"
+++

- [记忆、注意力、序列](https://towardsdatascience.com/memory-attention-sequences-37456d271992?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 复杂时空序列数据的处理被认为是神经网络需要处理的下一个大问题，本文深入浅出地介绍了注意力、记忆等相关的内容，从具体的应用上概括处理序列数据问题时需要注意的地方。

- [开放机器学习第9个话题：使用Python进行时序数据的分析](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 本文是类似课程内容的长文，内容非常基础，介绍了时序数据的定义和评价基准，预处理的方法和线性模型的使用方法。

- [谷歌指出文本嵌入模型包含偏差，以及它的影响](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 其实不止是文本嵌入模型存在这个，大部门的模型都有这个问题。谷歌使用了一个“单词嵌入相关性测试”（WEAT），用于检测词嵌入中的概念相关性，并用两个具体的例子来举证，并最后做出结论：WEAT有效但并无法完全避免这个问题，还需要更多的深入研究。

