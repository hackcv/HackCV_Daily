+++
author = "cvley"
categories = ["资讯日报"]
title = "第69期 HackCV 日报"
tags = ["深度学习","AI","机器学习","TensorFlow"]
date = "2017-12-10"
+++

- [2017年NIPS接收论文情况的统计分析](https://unsupervisedmethods.com/nips-accepted-papers-stats-26f124843aa0?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> NIPS是近年来AI学术领域发展最快的会议，今年从3240篇文章中录取了679篇，接收率21%。本文通过对今年这些接收的论文的作者和所属的研究机构进行分析，发现Google毫无疑问是研究领域最多的机构，而CMU在学术领域是开花结果最多的，Duke大学的Carin是参与发表论文最多的学者。其中也出现了中国科研团队的身影，比如清华大学、北京大学和腾讯的AI实验室。有志于进一步深造的朋友，可以好好看下这篇文章。

- [机器学习中分类问题的性能指标——第一部分](https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 看完这篇文章，就可以明白什么是混淆矩阵，以及分类问题中Accuracy和Precision的差别，Recall、Specificity以及F1得分具体是什么意思。

- [深度学习在公有云上的GPU开销效率上的性能测试](http://minimaxir.com/2017/11/benchmark-gpus/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 公有云是比较方便、按需使用的环境，本文在K80的单卡GPU、P100的单卡GPU、32核的CPU、16核的CPU环境下，使用TensorFlow和CNTK进行了一系列的深度学习模型训练，从训练时间和训练花费的角度进行了基准测试，发现P100性能高，但花费也多。

