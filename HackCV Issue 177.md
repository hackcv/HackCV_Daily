+++
author = "cvley"
categories = ["资讯日报"]
title = "第25期 HackCV 日报"
tags = ["深度学习","AI","机器学习","word2vec","TPU","通用解决方法"]
date = "2017-10-27"
+++

- [任意机器学习问题的通用解决方法](http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 作者在参加了上百场Kaggle竞赛后，总结出来的一套机器学习问题的解决方案，涉及到数据处理、模型应用，可以说干货十足，非常具有指导意义。

- [谷歌说机器学习芯片将让AI更快更高效](https://singularityhub.com/2017/04/23/google-says-machine-learning-chips-make-ai-faster-and-more-efficient/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 机器学习效果惊人，但速度看起来依旧不理想，于是就从底层硬件角度来加速。谷歌自研的TPU，对比CPU和GPU都有非常大的加速比。个人觉得，当一项技术发展到需要底层定制化时，差不多就到了成熟期了。

- [单词张量](http://multithreaded.stitchfix.com/blog/2017/10/25/word-tensors/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 停止使用word2vec的后续文章，张量分解是一个非常优雅直接的技术，在直接使用黑盒的深度学习之前，可以考虑使用张量分解，当然，还需要对数据比较了解才行。

