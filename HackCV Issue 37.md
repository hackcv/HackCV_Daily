+++
author = "cvley"
categories = ["资讯日报"]
title = "第133期 HackCV 日报"
tags = ["深度学习","机器学习","TensorFlow","word2vec"]
date = "2018-02-12"
+++

- [IMPALA：DMLab-30的可扩展分布式深度强化学习](https://deepmind.com/blog/impala-scalable-distributed-deeprl-dmlab-30/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 深度强化学习DeepRL已经在连续控制和棋牌游戏（围棋）等领域证明了自己，但目前还需要针对单任务进行具体agent的训练。DMLab-30是DeepMind实验室开源强化学习环境的一组新设计，而IMPALA是Importance-Weighted_Actor-Learner_Architectures，基于TensorFlow构建的分布式架构，可以获取数据吞吐的最大性能，其受A3C架构启发，但比A3C更高效精准。

- [机器学习元基准测试：GPU供应商（第二部分）](https://rare-technologies.com/machine-learning-benchmarks-hardware-providers-gpu-part-2/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 第一部分使用的是word2vec进行评测，本次使用的是情感分析模型，对比的平台有AWS、谷歌云平台、IBM、Hetzner、Paperspace和LeaderGPU，结果显示Paperspace在性能和开销方面做的明显比其他家要好。

- [使用哪种GPU进行深度学习：我的经验和建议](http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/?from=hackcv&hmsr=hackcv.com&utm_medium=hackcv.com&utm_source=hackcv.com)

> 这篇文章持续更新了三年，由此看出这篇文章还是很有参考价值的。从最后的建议看，基本是GTX_1050_Ti、GTX_1060、GTX_1070、GTX_1080、GTX_1080_Ti和Titan系列，简单来说，个人的话，使用GTX_1080或者相似性能的GPU就足够了。

